{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Woof_128_twist.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "LP3vVSWMBz1L",
        "6C-1pE45Bz1l",
        "pLmt0ISPBz2w"
      ],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/liuyao12/imagenette_experiments/blob/master/ResNet_twist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GM0cNcW2Bzz4",
        "colab_type": "text"
      },
      "source": [
        "# ResNet with a Twist\n",
        "\n",
        "> with depthwise (x4) + Ranger + Mish + SA + MaxBlurPool + ResTrick\n",
        "\n",
        "See blog https://liuyao12.github.io/blog/research/2020/03/07/Conv-Twist.html\n",
        "\n",
        "See summary at https://forums.fast.ai/t/imagenette-imagewoof-leaderboards/45822/47?u=liuyao "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXBTriT1fmXE",
        "colab_type": "text"
      },
      "source": [
        "## Imagewoof Leaderboard\n",
        "\n",
        "Imagewoof is a small subset of ImageNet, consisting of 10 dog breeds, courtesy of fast.ai and Jeremy Howard.\n",
        "\n",
        "(Imagewoof2, with a 70/30 train/test ratio)\n",
        "\n",
        "| Size (px) | Epochs | SoTA| x2 | x4 | x4 twist | x6 | x4 double | runs |\n",
        "|--|--|--| --|--| --|--|--|--|\n",
        "|128|5|73.37|75.19|76.27||76.61| **82.12**|5, mean\n",
        "|128|20|85.52|85.18|86.22||86.27| **88.93**|5, mean\n",
        "|128|80|87.20|87.70|87.83||87.65| **90.15**|1\n",
        "|128|200|87.20|\n",
        "|192|5|77.87|79.86|81.15|80.73|| **82.69**|5, mean\n",
        "|192|20|87.85|88.12|88.37|88.28|\n",
        "|192|80|89.21|90.30|90.25|89.38|90.37| **92.08** |\n",
        "|192|200|89.54\n",
        "|256|5|\n",
        "|256|20|\n",
        "|256|80|\n",
        "|256|200|\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrD1-te_Bzz7",
        "colab_type": "text"
      },
      "source": [
        "# setup and imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UteAROmqBzz9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install git+https://github.com/ayasyrev/model_constructor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XnsPVNrkTfV3",
        "colab": {}
      },
      "source": [
        "pip install git+https://github.com/ayasyrev/imagenette_experiments"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-OCjxGCBz0J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai.basic_train import *\n",
        "from fastai.vision import *\n",
        "# from fastai.script import *"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPNF3XKWBz0O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pip install kornia\n",
        "from kornia.contrib import MaxBlurPool2d"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPGwrk6TBz0U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from imagenette_experiments.train_utils import *\n",
        "from model_constructor.net import Net, act_fn\n",
        "from model_constructor.layers import SimpleSelfAttention, ConvLayer"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U63Mcb1lBz0p",
        "colab_type": "text"
      },
      "source": [
        "# ResBlock"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbKrwk-649_y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MnM(nn.Module): # Mix and Multiply\n",
        "    def __init__(self, channels, group_size):\n",
        "        super().__init__()\n",
        "        self.channels = channels\n",
        "        self.gs = group_size\n",
        "        n = channels//group_size*4\n",
        "        self.conv = nn.Conv2d(n, n*2, 1, groups=n, bias=True)\n",
        "        self.XY = None\n",
        "\n",
        "    def forward(self, x): \n",
        "        N,C,H,W = x.size()\n",
        "        # x1 = x.view(N,-1,self.gs,H,W)[:,:,:-2].reshape(N,-1,H,W)\n",
        "        x2 = x.view(N,-1,self.gs,H,W)[:,:,:4].reshape(N,-1,H,W)\n",
        "        if self.XY is None:\n",
        "            XX = torch.from_numpy(np.indices((1,H,W))[2]*2/W-1)\n",
        "            YY = torch.from_numpy(np.indices((1,H,W))[1]*2/H-1)\n",
        "            g = self.channels//self.gs*4\n",
        "            self.XY = torch.cat([XX,YY]*g, dim=0).to(x.device).type(x.dtype)\n",
        "        twist = self.conv(x2) * self.XY\n",
        "        twist = torch.sum(twist.view(N,-1,2,4,H,W), dim=2).reshape(N,-1,H,W)\n",
        "        return torch.cat([x, twist], dim=1)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kY7y9c99Bz0q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NewLayer(nn.Sequential):\n",
        "    \"\"\"Basic conv layers block\"\"\"\n",
        "    def __init__(self, ni, nf, ks=3, stride=1,\n",
        "            act=True,  act_fn=nn.ReLU(inplace=True),\n",
        "            bn_layer=True, bn_1st=True, zero_bn=False,\n",
        "            padding=None, bias=False, groups=1, **kwargs):\n",
        "\n",
        "        if padding==None: padding = ks//2\n",
        "        if ks==3 and groups==1:  # to be used for the \"stem\" of ResNet\n",
        "          # if ni==3: stride = 2\n",
        "          layers = [('Conv3x3', nn.Conv2d(ni, ni*dm, 3, stride=stride, padding=1, bias=bias, groups=ni)),\n",
        "                    ('Conv1x1', nn.Conv2d(ni*dm, nf, 1, bias=bias, groups=1))]\n",
        "        else:\n",
        "          layers = [('Conv{}x{}'.format(ks,ks), \n",
        "                      nn.Conv2d(ni, nf, ks, stride=stride, padding=padding, bias=bias, groups=groups))]\n",
        "\n",
        "        act_bn = [('act_fn', act_fn)] if act else []\n",
        "        if bn_layer:\n",
        "            bn = nn.BatchNorm2d(nf)\n",
        "            nn.init.constant_(bn.weight, 0. if zero_bn else 1.)\n",
        "            act_bn += [('bn', bn)]\n",
        "        if bn_1st: act_bn.reverse()\n",
        "        layers += act_bn\n",
        "        super().__init__(OrderedDict(layers))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVLFz9nhBz0x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NewResBlock(Module):\n",
        "    def __init__(self, expansion, ni, nh, stride=1,\n",
        "                 conv_layer=ConvLayer, act_fn=act_fn, zero_bn=True, bn_1st=True,\n",
        "                 pool=nn.AvgPool2d(2, ceil_mode=True), sa=False, sym=False, groups=1):\n",
        "        nf,ni = nh*expansion,ni*expansion\n",
        "        conv_layer = NewLayer\n",
        "        self.reduce = noop if stride==1 else pool\n",
        "        layers  = [(f\"conv_0\", conv_layer(ni, nh, 3, act_fn=act_fn, bn_1st=bn_1st)),\n",
        "                   (f\"conv_1\", conv_layer(ni, nf, 3, zero_bn=zero_bn, act=False, bn_layer=True))\n",
        "        ] if expansion == 1 else [\n",
        "                   (f\"conv_0\", conv_layer(ni, nh, 1, act_fn=act_fn, bn_1st=bn_1st)),\n",
        "                   # (f\"conv_1\", conv_layer(nh, nh, 3, act_fn=act_fn, bn_1st=bn_1st)),\n",
        "                   (f\"conv_1\", conv_layer(nh, nh*dm, 3, groups=nh, act_fn=act_fn, bn_1st=bn_1st)),\n",
        "                   # (f\"conv_1\", conv_layer(nh, nh*dm, 3, groups=nh, act=False, bn_layer=False)),\n",
        "                   (f\"MnM\", MnM(nf, dm)),\n",
        "                   (f\"conv_2\", conv_layer(nh*(dm+4), nf, 1, zero_bn=zero_bn, act=False, bn_1st=bn_1st))\n",
        "        ]\n",
        "        if sa: layers.append(('sa', SimpleSelfAttention(nf,ks=1,sym=sym)))\n",
        "        self.convs = nn.Sequential(OrderedDict(layers))\n",
        "        self.idconv = noop if ni==nf else conv_layer(ni, nf, 1, act=False, bn_1st=bn_1st)\n",
        "        self.merge = act_fn\n",
        "\n",
        "    def forward(self, x):\n",
        "        o = self.reduce(x)\n",
        "        return self.merge(self.convs(o) + self.idconv(o))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XroIp4GcBz07",
        "colab_type": "text"
      },
      "source": [
        "# Model Constructor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTrZVV81Bz1G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Net(c_out=10, layers=[3,6,8,3], expansion=4)\n",
        "model.block = NewResBlock\n",
        "model.conv_layer = NewLayer # for the stem\n",
        "pool = MaxBlurPool2d(3, True)\n",
        "model.pool = pool\n",
        "model.stem_sizes = [3,32,64,64]\n",
        "model.act_fn = Mish()\n",
        "model.sa = True"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCDxE73yuq_5",
        "colab_type": "text"
      },
      "source": [
        "## Experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JfDW5iqPVE4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d5ae73b0-d3a1-4045-bd9a-4dd725a711c2"
      },
      "source": [
        "dm = 4\n",
        "res = dict()\n",
        "for ep in [80]: #*5 + [20] + [80]:\n",
        "    mixup=0 if ep<=20 else 0.2\n",
        "    learn = get_learn(model=model, size=192, bs=16, mixup=mixup)\n",
        "    learn.fit_fc(ep, lr=4e-3, moms=(0.95,0.95), start_pct=0.72)\n",
        "    acc = learn.recorder.metrics[-1][0].item()\n",
        "    res[ep] = res[ep] + [acc] if ep in res else [acc]\n",
        "    print('{} epochs: {} ({} runs)'.format(ep, sum(res[ep])/len(res[ep]), len(res[ep])))\n",
        "print('depth multiplier={}'.format(dm), {ep: sum(res[ep])/len(res[ep]) for ep in res})"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://s3.amazonaws.com/fast-ai-imageclas/imagewoof2.tgz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "data path   /root/.fastai/data/imagewoof2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Learn path /root/.fastai/data/imagewoof2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>top_k_accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.007803</td>\n",
              "      <td>1.790987</td>\n",
              "      <td>0.414100</td>\n",
              "      <td>0.878086</td>\n",
              "      <td>03:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.794687</td>\n",
              "      <td>1.500919</td>\n",
              "      <td>0.561212</td>\n",
              "      <td>0.937389</td>\n",
              "      <td>03:33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.620749</td>\n",
              "      <td>1.284334</td>\n",
              "      <td>0.673199</td>\n",
              "      <td>0.956986</td>\n",
              "      <td>03:33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.526108</td>\n",
              "      <td>1.198381</td>\n",
              "      <td>0.712650</td>\n",
              "      <td>0.966404</td>\n",
              "      <td>03:33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.462588</td>\n",
              "      <td>1.147985</td>\n",
              "      <td>0.740646</td>\n",
              "      <td>0.972512</td>\n",
              "      <td>03:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.375338</td>\n",
              "      <td>1.057145</td>\n",
              "      <td>0.782387</td>\n",
              "      <td>0.972258</td>\n",
              "      <td>03:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.358792</td>\n",
              "      <td>1.044155</td>\n",
              "      <td>0.780606</td>\n",
              "      <td>0.976584</td>\n",
              "      <td>03:33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.303343</td>\n",
              "      <td>0.977458</td>\n",
              "      <td>0.812166</td>\n",
              "      <td>0.977093</td>\n",
              "      <td>03:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.248779</td>\n",
              "      <td>0.964249</td>\n",
              "      <td>0.821838</td>\n",
              "      <td>0.975821</td>\n",
              "      <td>03:33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.200880</td>\n",
              "      <td>0.952638</td>\n",
              "      <td>0.819292</td>\n",
              "      <td>0.978875</td>\n",
              "      <td>03:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.196049</td>\n",
              "      <td>0.963082</td>\n",
              "      <td>0.820056</td>\n",
              "      <td>0.977348</td>\n",
              "      <td>03:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>1.177993</td>\n",
              "      <td>0.940718</td>\n",
              "      <td>0.827691</td>\n",
              "      <td>0.980911</td>\n",
              "      <td>03:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>1.112221</td>\n",
              "      <td>0.905222</td>\n",
              "      <td>0.838636</td>\n",
              "      <td>0.983456</td>\n",
              "      <td>03:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>1.127327</td>\n",
              "      <td>0.885119</td>\n",
              "      <td>0.851107</td>\n",
              "      <td>0.984474</td>\n",
              "      <td>03:33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>1.054359</td>\n",
              "      <td>0.879499</td>\n",
              "      <td>0.850344</td>\n",
              "      <td>0.986256</td>\n",
              "      <td>03:33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>1.113400</td>\n",
              "      <td>0.871822</td>\n",
              "      <td>0.851107</td>\n",
              "      <td>0.984983</td>\n",
              "      <td>03:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>1.065508</td>\n",
              "      <td>0.853116</td>\n",
              "      <td>0.868414</td>\n",
              "      <td>0.983965</td>\n",
              "      <td>03:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>1.070289</td>\n",
              "      <td>0.878346</td>\n",
              "      <td>0.849580</td>\n",
              "      <td>0.983456</td>\n",
              "      <td>03:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>1.040509</td>\n",
              "      <td>0.864181</td>\n",
              "      <td>0.860779</td>\n",
              "      <td>0.982693</td>\n",
              "      <td>03:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>1.019969</td>\n",
              "      <td>0.867150</td>\n",
              "      <td>0.856961</td>\n",
              "      <td>0.986256</td>\n",
              "      <td>03:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.011127</td>\n",
              "      <td>0.858038</td>\n",
              "      <td>0.861797</td>\n",
              "      <td>0.981420</td>\n",
              "      <td>03:33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>1.013803</td>\n",
              "      <td>0.873464</td>\n",
              "      <td>0.854670</td>\n",
              "      <td>0.982947</td>\n",
              "      <td>03:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.977144</td>\n",
              "      <td>0.849807</td>\n",
              "      <td>0.866633</td>\n",
              "      <td>0.983711</td>\n",
              "      <td>03:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.996977</td>\n",
              "      <td>0.848435</td>\n",
              "      <td>0.864342</td>\n",
              "      <td>0.985238</td>\n",
              "      <td>03:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.965440</td>\n",
              "      <td>0.850357</td>\n",
              "      <td>0.862815</td>\n",
              "      <td>0.980148</td>\n",
              "      <td>03:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.988976</td>\n",
              "      <td>0.888444</td>\n",
              "      <td>0.840672</td>\n",
              "      <td>0.986511</td>\n",
              "      <td>03:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.973069</td>\n",
              "      <td>0.861808</td>\n",
              "      <td>0.864851</td>\n",
              "      <td>0.981675</td>\n",
              "      <td>03:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.964192</td>\n",
              "      <td>0.838240</td>\n",
              "      <td>0.868923</td>\n",
              "      <td>0.980402</td>\n",
              "      <td>03:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.933393</td>\n",
              "      <td>0.856793</td>\n",
              "      <td>0.859252</td>\n",
              "      <td>0.983456</td>\n",
              "      <td>03:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.978527</td>\n",
              "      <td>0.871089</td>\n",
              "      <td>0.855434</td>\n",
              "      <td>0.982438</td>\n",
              "      <td>03:35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.955656</td>\n",
              "      <td>0.861020</td>\n",
              "      <td>0.862560</td>\n",
              "      <td>0.983202</td>\n",
              "      <td>03:35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.928080</td>\n",
              "      <td>0.871131</td>\n",
              "      <td>0.861033</td>\n",
              "      <td>0.979639</td>\n",
              "      <td>03:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.928846</td>\n",
              "      <td>0.847624</td>\n",
              "      <td>0.864851</td>\n",
              "      <td>0.982947</td>\n",
              "      <td>03:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.937302</td>\n",
              "      <td>0.862849</td>\n",
              "      <td>0.860270</td>\n",
              "      <td>0.980148</td>\n",
              "      <td>03:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.913456</td>\n",
              "      <td>0.851028</td>\n",
              "      <td>0.863324</td>\n",
              "      <td>0.983202</td>\n",
              "      <td>03:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.946231</td>\n",
              "      <td>0.838144</td>\n",
              "      <td>0.867905</td>\n",
              "      <td>0.981420</td>\n",
              "      <td>03:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.942067</td>\n",
              "      <td>0.850046</td>\n",
              "      <td>0.866633</td>\n",
              "      <td>0.982438</td>\n",
              "      <td>03:35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.937414</td>\n",
              "      <td>0.867450</td>\n",
              "      <td>0.855943</td>\n",
              "      <td>0.981166</td>\n",
              "      <td>03:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.916425</td>\n",
              "      <td>0.832102</td>\n",
              "      <td>0.871978</td>\n",
              "      <td>0.983456</td>\n",
              "      <td>03:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.919455</td>\n",
              "      <td>0.856762</td>\n",
              "      <td>0.868160</td>\n",
              "      <td>0.978366</td>\n",
              "      <td>03:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.920704</td>\n",
              "      <td>0.839484</td>\n",
              "      <td>0.864342</td>\n",
              "      <td>0.983711</td>\n",
              "      <td>03:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.915165</td>\n",
              "      <td>0.866935</td>\n",
              "      <td>0.860015</td>\n",
              "      <td>0.975566</td>\n",
              "      <td>03:35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.919874</td>\n",
              "      <td>0.849979</td>\n",
              "      <td>0.868160</td>\n",
              "      <td>0.983202</td>\n",
              "      <td>03:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.911138</td>\n",
              "      <td>0.851838</td>\n",
              "      <td>0.862815</td>\n",
              "      <td>0.982693</td>\n",
              "      <td>03:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.871670</td>\n",
              "      <td>0.827536</td>\n",
              "      <td>0.876050</td>\n",
              "      <td>0.981929</td>\n",
              "      <td>03:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.905919</td>\n",
              "      <td>0.852639</td>\n",
              "      <td>0.861288</td>\n",
              "      <td>0.982184</td>\n",
              "      <td>03:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.878448</td>\n",
              "      <td>0.840757</td>\n",
              "      <td>0.869178</td>\n",
              "      <td>0.982184</td>\n",
              "      <td>03:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.871678</td>\n",
              "      <td>0.842638</td>\n",
              "      <td>0.867396</td>\n",
              "      <td>0.981675</td>\n",
              "      <td>03:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.884015</td>\n",
              "      <td>0.843935</td>\n",
              "      <td>0.869687</td>\n",
              "      <td>0.981166</td>\n",
              "      <td>03:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.868243</td>\n",
              "      <td>0.849926</td>\n",
              "      <td>0.868160</td>\n",
              "      <td>0.978875</td>\n",
              "      <td>03:35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.870132</td>\n",
              "      <td>0.832294</td>\n",
              "      <td>0.873759</td>\n",
              "      <td>0.979893</td>\n",
              "      <td>03:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>0.910625</td>\n",
              "      <td>0.827964</td>\n",
              "      <td>0.877322</td>\n",
              "      <td>0.979384</td>\n",
              "      <td>03:35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>0.896894</td>\n",
              "      <td>0.852151</td>\n",
              "      <td>0.865869</td>\n",
              "      <td>0.981166</td>\n",
              "      <td>03:35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>0.884392</td>\n",
              "      <td>0.853437</td>\n",
              "      <td>0.864597</td>\n",
              "      <td>0.981675</td>\n",
              "      <td>03:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>0.879839</td>\n",
              "      <td>0.855102</td>\n",
              "      <td>0.866633</td>\n",
              "      <td>0.980148</td>\n",
              "      <td>03:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>0.894052</td>\n",
              "      <td>0.849963</td>\n",
              "      <td>0.870960</td>\n",
              "      <td>0.979130</td>\n",
              "      <td>03:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>0.887490</td>\n",
              "      <td>0.845458</td>\n",
              "      <td>0.870196</td>\n",
              "      <td>0.979130</td>\n",
              "      <td>03:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>0.865249</td>\n",
              "      <td>0.841969</td>\n",
              "      <td>0.869941</td>\n",
              "      <td>0.981420</td>\n",
              "      <td>03:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>0.884026</td>\n",
              "      <td>0.835226</td>\n",
              "      <td>0.870450</td>\n",
              "      <td>0.981420</td>\n",
              "      <td>03:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>0.865137</td>\n",
              "      <td>0.838561</td>\n",
              "      <td>0.874777</td>\n",
              "      <td>0.981929</td>\n",
              "      <td>03:35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.869268</td>\n",
              "      <td>0.857242</td>\n",
              "      <td>0.857979</td>\n",
              "      <td>0.980657</td>\n",
              "      <td>03:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>61</td>\n",
              "      <td>0.871260</td>\n",
              "      <td>0.834656</td>\n",
              "      <td>0.871469</td>\n",
              "      <td>0.979130</td>\n",
              "      <td>03:35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>0.843610</td>\n",
              "      <td>0.829089</td>\n",
              "      <td>0.874014</td>\n",
              "      <td>0.980657</td>\n",
              "      <td>03:35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63</td>\n",
              "      <td>0.864108</td>\n",
              "      <td>0.837815</td>\n",
              "      <td>0.872232</td>\n",
              "      <td>0.981166</td>\n",
              "      <td>03:35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>0.839498</td>\n",
              "      <td>0.829955</td>\n",
              "      <td>0.871723</td>\n",
              "      <td>0.978621</td>\n",
              "      <td>03:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>0.870649</td>\n",
              "      <td>0.812242</td>\n",
              "      <td>0.883685</td>\n",
              "      <td>0.981675</td>\n",
              "      <td>03:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>0.844536</td>\n",
              "      <td>0.828908</td>\n",
              "      <td>0.879613</td>\n",
              "      <td>0.980657</td>\n",
              "      <td>03:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>67</td>\n",
              "      <td>0.856569</td>\n",
              "      <td>0.807731</td>\n",
              "      <td>0.880631</td>\n",
              "      <td>0.982438</td>\n",
              "      <td>03:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68</td>\n",
              "      <td>0.834252</td>\n",
              "      <td>0.819127</td>\n",
              "      <td>0.877068</td>\n",
              "      <td>0.983965</td>\n",
              "      <td>03:35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>69</td>\n",
              "      <td>0.793922</td>\n",
              "      <td>0.795812</td>\n",
              "      <td>0.886740</td>\n",
              "      <td>0.983456</td>\n",
              "      <td>03:35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.818848</td>\n",
              "      <td>0.802873</td>\n",
              "      <td>0.886740</td>\n",
              "      <td>0.981420</td>\n",
              "      <td>03:35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>71</td>\n",
              "      <td>0.798262</td>\n",
              "      <td>0.797771</td>\n",
              "      <td>0.891066</td>\n",
              "      <td>0.982693</td>\n",
              "      <td>03:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>0.794022</td>\n",
              "      <td>0.782895</td>\n",
              "      <td>0.891830</td>\n",
              "      <td>0.982438</td>\n",
              "      <td>03:35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>73</td>\n",
              "      <td>0.780655</td>\n",
              "      <td>0.780443</td>\n",
              "      <td>0.889285</td>\n",
              "      <td>0.983202</td>\n",
              "      <td>03:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74</td>\n",
              "      <td>0.794548</td>\n",
              "      <td>0.777584</td>\n",
              "      <td>0.895393</td>\n",
              "      <td>0.982184</td>\n",
              "      <td>03:35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>0.794356</td>\n",
              "      <td>0.771277</td>\n",
              "      <td>0.894630</td>\n",
              "      <td>0.985238</td>\n",
              "      <td>03:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>76</td>\n",
              "      <td>0.786190</td>\n",
              "      <td>0.767445</td>\n",
              "      <td>0.897175</td>\n",
              "      <td>0.984220</td>\n",
              "      <td>03:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>77</td>\n",
              "      <td>0.773923</td>\n",
              "      <td>0.767946</td>\n",
              "      <td>0.897684</td>\n",
              "      <td>0.983202</td>\n",
              "      <td>03:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>78</td>\n",
              "      <td>0.782433</td>\n",
              "      <td>0.768812</td>\n",
              "      <td>0.896157</td>\n",
              "      <td>0.983711</td>\n",
              "      <td>03:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>79</td>\n",
              "      <td>0.792370</td>\n",
              "      <td>0.768111</td>\n",
              "      <td>0.896411</td>\n",
              "      <td>0.983711</td>\n",
              "      <td>03:34</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/imagenette_experiments/train_utils.py:150: UserWarning: This overload of addcmul_ is deprecated:\n",
            "\taddcmul_(Number value, Tensor tensor1, Tensor tensor2)\n",
            "Consider using one of the following signatures instead:\n",
            "\taddcmul_(Tensor tensor1, Tensor tensor2, *, Number value) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
            "  exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "80 epochs: 0.8964112997055054 (1 runs)\n",
            "depth multiplier=4 {80: 0.8964112997055054}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyxBJyajoKbg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "f97f826a-45cf-4b2e-b196-e90ced141075"
      },
      "source": [
        "print('depth multiplier={}'.format(dm), {ep: sum(res[ep])/len(res[ep]) for ep in res})\n",
        "for i in range(80):\n",
        "  print(i, learn.recorder.val_losses[i].item(), learn.recorder.metrics[i][0].item())"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-59a275e5a08c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'depth multiplier={}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mep\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecorder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_losses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecorder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'dm' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2IWhFs0T3r5",
        "colab_type": "text"
      },
      "source": [
        "## Experiment with changing model during training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGf7A96cS9y9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "state = learn.model.state_dict()"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJshCxYpTIRM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "325a6a74-8fd5-4fb2-ff6f-a746fd78fda4"
      },
      "source": [
        "epochs = 10\n",
        "mixup = 0 if epochs<=20 else 0.2\n",
        "learn2 = get_learn(model=model, size=192, bs=16, mixup=mixup)\n",
        "learn2.model.load_state_dict(state)\n",
        "print(learn2.validate())"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data path   /root/.fastai/data/imagewoof2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Learn path /root/.fastai/data/imagewoof2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0.7742255, tensor(0.8972), tensor(0.9842)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcIoXbxGTWVE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "40bac60b-7e7d-4de9-a5c4-49a962f5af80"
      },
      "source": [
        "learn2.fit_fc(10, lr=4e-6, moms=(0.95,0.95), start_pct=0.72)\n",
        "print(learn2.recorder.metrics[-1][0].item())"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>top_k_accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.535328</td>\n",
              "      <td>0.776316</td>\n",
              "      <td>0.895902</td>\n",
              "      <td>0.983456</td>\n",
              "      <td>02:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.534004</td>\n",
              "      <td>0.773021</td>\n",
              "      <td>0.898702</td>\n",
              "      <td>0.984983</td>\n",
              "      <td>02:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.531789</td>\n",
              "      <td>0.771603</td>\n",
              "      <td>0.896920</td>\n",
              "      <td>0.983965</td>\n",
              "      <td>02:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.527236</td>\n",
              "      <td>0.771580</td>\n",
              "      <td>0.898193</td>\n",
              "      <td>0.983965</td>\n",
              "      <td>02:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.532100</td>\n",
              "      <td>0.770064</td>\n",
              "      <td>0.899211</td>\n",
              "      <td>0.984474</td>\n",
              "      <td>02:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.528425</td>\n",
              "      <td>0.768916</td>\n",
              "      <td>0.898956</td>\n",
              "      <td>0.984983</td>\n",
              "      <td>02:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.531735</td>\n",
              "      <td>0.769262</td>\n",
              "      <td>0.897938</td>\n",
              "      <td>0.985747</td>\n",
              "      <td>02:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.532737</td>\n",
              "      <td>0.767670</td>\n",
              "      <td>0.898193</td>\n",
              "      <td>0.985747</td>\n",
              "      <td>02:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.531163</td>\n",
              "      <td>0.768917</td>\n",
              "      <td>0.898193</td>\n",
              "      <td>0.984729</td>\n",
              "      <td>02:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.533564</td>\n",
              "      <td>0.768265</td>\n",
              "      <td>0.897429</td>\n",
              "      <td>0.984729</td>\n",
              "      <td>02:05</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.897429347038269\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijxp4I0gYkUi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a1768305-c63c-4d58-8275-518e291ff70e"
      },
      "source": [
        "channels = 0\n",
        "for name in state:\n",
        "  if 'Conv3x3' in name and channels==0:\n",
        "    a,b,c,d = state[name].size()\n",
        "    double = state[name].unsqueeze(1).expand(a,2,b,c,d).reshape(a*2,b,c,d)\n",
        "    state[name] = double / 1.414\n",
        "    channels = a\n",
        "  if 'Conv1x1' in name and state[name].size()[1]==channels:\n",
        "    a,b,c,d = state[name].size()\n",
        "    double = state[name].unsqueeze(2).expand(a,b,2,c,d).reshape(a,b*2,c,d)\n",
        "    state[name] = double / 1.414\n",
        "    channels = 0\n",
        "print('done doubling')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done doubling\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AsUVyI9YuHw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "c0bba067-c740-4961-f973-01b4778ac36c"
      },
      "source": [
        "dm = 4\n",
        "mixup = 0 if epochs<=20 else 0.2\n",
        "learn2 = get_learn(model=model, size=192, bs=16, mixup=mixup)\n",
        "learn2.model.load_state_dict(state)\n",
        "print(learn2.validate())"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data path   /root/.fastai/data/imagewoof2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Learn path /root/.fastai/data/imagewoof2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[0.7742505, tensor(0.8972), tensor(0.9842)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19M4ETd6mqAn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "67efa92f-a066-427f-99b6-95434dd1c499"
      },
      "source": [
        "learn2.fit_fc(10, lr=4e-4, moms=(0.95,0.95), start_pct=0.72)\n",
        "print(learn2.recorder.metrics[-1][0].item())"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>top_k_accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.531288</td>\n",
              "      <td>0.768768</td>\n",
              "      <td>0.896157</td>\n",
              "      <td>0.984983</td>\n",
              "      <td>02:27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.526129</td>\n",
              "      <td>0.769331</td>\n",
              "      <td>0.894375</td>\n",
              "      <td>0.983202</td>\n",
              "      <td>02:27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.528508</td>\n",
              "      <td>0.773641</td>\n",
              "      <td>0.894884</td>\n",
              "      <td>0.980148</td>\n",
              "      <td>02:27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.527456</td>\n",
              "      <td>0.772259</td>\n",
              "      <td>0.894121</td>\n",
              "      <td>0.981675</td>\n",
              "      <td>02:27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.524152</td>\n",
              "      <td>0.772953</td>\n",
              "      <td>0.894884</td>\n",
              "      <td>0.982947</td>\n",
              "      <td>02:27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.521762</td>\n",
              "      <td>0.776454</td>\n",
              "      <td>0.891575</td>\n",
              "      <td>0.980911</td>\n",
              "      <td>02:27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.525762</td>\n",
              "      <td>0.774231</td>\n",
              "      <td>0.896157</td>\n",
              "      <td>0.981166</td>\n",
              "      <td>02:27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.522501</td>\n",
              "      <td>0.770750</td>\n",
              "      <td>0.897938</td>\n",
              "      <td>0.981675</td>\n",
              "      <td>02:26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.522169</td>\n",
              "      <td>0.769787</td>\n",
              "      <td>0.894884</td>\n",
              "      <td>0.982947</td>\n",
              "      <td>02:27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.518775</td>\n",
              "      <td>0.765697</td>\n",
              "      <td>0.895648</td>\n",
              "      <td>0.982438</td>\n",
              "      <td>02:26</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.8956477642059326\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83WPPdxXerpU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "d45a7007-caf4-4467-957f-95d72a1feb5c"
      },
      "source": [
        "learn2.fit_fc(10, lr=4e-5, moms=(0.95,0.95), start_pct=0.72)\n",
        "print(learn2.recorder.metrics[-1][0].item())"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>top_k_accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.532618</td>\n",
              "      <td>0.770861</td>\n",
              "      <td>0.897684</td>\n",
              "      <td>0.983965</td>\n",
              "      <td>02:27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.532992</td>\n",
              "      <td>0.766575</td>\n",
              "      <td>0.898447</td>\n",
              "      <td>0.985238</td>\n",
              "      <td>02:27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.530577</td>\n",
              "      <td>0.767157</td>\n",
              "      <td>0.897429</td>\n",
              "      <td>0.984729</td>\n",
              "      <td>02:27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.524347</td>\n",
              "      <td>0.767554</td>\n",
              "      <td>0.898447</td>\n",
              "      <td>0.985238</td>\n",
              "      <td>02:27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.530132</td>\n",
              "      <td>0.766334</td>\n",
              "      <td>0.897684</td>\n",
              "      <td>0.984474</td>\n",
              "      <td>02:27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.527259</td>\n",
              "      <td>0.765086</td>\n",
              "      <td>0.896157</td>\n",
              "      <td>0.984729</td>\n",
              "      <td>02:27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.524162</td>\n",
              "      <td>0.766871</td>\n",
              "      <td>0.896920</td>\n",
              "      <td>0.984474</td>\n",
              "      <td>02:27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.529729</td>\n",
              "      <td>0.765050</td>\n",
              "      <td>0.898702</td>\n",
              "      <td>0.986002</td>\n",
              "      <td>02:27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.533118</td>\n",
              "      <td>0.765301</td>\n",
              "      <td>0.898956</td>\n",
              "      <td>0.983711</td>\n",
              "      <td>02:27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.530292</td>\n",
              "      <td>0.763030</td>\n",
              "      <td>0.899211</td>\n",
              "      <td>0.984983</td>\n",
              "      <td>02:27</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.8992109894752502\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnc3nZQjY7LU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "e8460ec7-7f89-4810-c091-31cfc3091ca3"
      },
      "source": [
        "learn2.fit_fc(10, lr=4e-6, moms=(0.95,0.95), start_pct=0.72)\n",
        "print(learn2.recorder.metrics[-1][0].item())"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>top_k_accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.533471</td>\n",
              "      <td>0.772939</td>\n",
              "      <td>0.898447</td>\n",
              "      <td>0.984220</td>\n",
              "      <td>02:28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.533423</td>\n",
              "      <td>0.770602</td>\n",
              "      <td>0.898702</td>\n",
              "      <td>0.985238</td>\n",
              "      <td>02:28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.534358</td>\n",
              "      <td>0.771039</td>\n",
              "      <td>0.899211</td>\n",
              "      <td>0.983202</td>\n",
              "      <td>02:27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.538733</td>\n",
              "      <td>0.769044</td>\n",
              "      <td>0.898702</td>\n",
              "      <td>0.985238</td>\n",
              "      <td>02:28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.535500</td>\n",
              "      <td>0.769227</td>\n",
              "      <td>0.898447</td>\n",
              "      <td>0.984983</td>\n",
              "      <td>02:28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.524419</td>\n",
              "      <td>0.770779</td>\n",
              "      <td>0.898193</td>\n",
              "      <td>0.983965</td>\n",
              "      <td>02:28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.534346</td>\n",
              "      <td>0.769639</td>\n",
              "      <td>0.898193</td>\n",
              "      <td>0.983965</td>\n",
              "      <td>02:28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.533792</td>\n",
              "      <td>0.768531</td>\n",
              "      <td>0.899975</td>\n",
              "      <td>0.984983</td>\n",
              "      <td>02:28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.532404</td>\n",
              "      <td>0.770487</td>\n",
              "      <td>0.897175</td>\n",
              "      <td>0.984220</td>\n",
              "      <td>02:28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.529191</td>\n",
              "      <td>0.768891</td>\n",
              "      <td>0.899211</td>\n",
              "      <td>0.984729</td>\n",
              "      <td>02:28</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.8992109894752502\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tj0OrEg8rEuk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "56c01c97-bb0d-47e0-a418-112d186db651"
      },
      "source": [
        "dm = 6\n",
        "for ep in [80]: #*5 + [20] + [80]:\n",
        "    mixup=0 if ep<=20 else 0.2\n",
        "    learn = get_learn(model=model, size=192, bs=16, mixup=mixup)\n",
        "    learn.fit_fc(ep, lr=4e-3, moms=(0.95,0.95), start_pct=0.72)\n",
        "    acc = learn.recorder.metrics[-1][0].item()\n",
        "    res[ep] = res[ep] + [acc] if ep in res else [acc]\n",
        "    print('{} epochs: {} ({} runs)'.format(ep, sum(res[ep])/len(res[ep]), len(res[ep])))\n",
        "print('depth multiplier={}'.format(dm), {ep: sum(res[ep])/len(res[ep]) for ep in res})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data path   /root/.fastai/data/imagewoof2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Learn path /root/.fastai/data/imagewoof2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>top_k_accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.020703</td>\n",
              "      <td>1.802997</td>\n",
              "      <td>0.427335</td>\n",
              "      <td>0.867651</td>\n",
              "      <td>03:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.779585</td>\n",
              "      <td>1.501510</td>\n",
              "      <td>0.564775</td>\n",
              "      <td>0.925681</td>\n",
              "      <td>03:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.654090</td>\n",
              "      <td>1.303978</td>\n",
              "      <td>0.665564</td>\n",
              "      <td>0.956732</td>\n",
              "      <td>03:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.513084</td>\n",
              "      <td>1.190918</td>\n",
              "      <td>0.718503</td>\n",
              "      <td>0.963858</td>\n",
              "      <td>03:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.462979</td>\n",
              "      <td>1.105817</td>\n",
              "      <td>0.762026</td>\n",
              "      <td>0.970476</td>\n",
              "      <td>03:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.379337</td>\n",
              "      <td>1.063350</td>\n",
              "      <td>0.775515</td>\n",
              "      <td>0.973530</td>\n",
              "      <td>03:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.323550</td>\n",
              "      <td>1.003739</td>\n",
              "      <td>0.801731</td>\n",
              "      <td>0.972767</td>\n",
              "      <td>03:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.273628</td>\n",
              "      <td>0.989483</td>\n",
              "      <td>0.810130</td>\n",
              "      <td>0.980657</td>\n",
              "      <td>03:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.264744</td>\n",
              "      <td>1.045115</td>\n",
              "      <td>0.777806</td>\n",
              "      <td>0.977348</td>\n",
              "      <td>03:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.220185</td>\n",
              "      <td>0.947007</td>\n",
              "      <td>0.821583</td>\n",
              "      <td>0.978621</td>\n",
              "      <td>03:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.155905</td>\n",
              "      <td>0.961251</td>\n",
              "      <td>0.826928</td>\n",
              "      <td>0.977857</td>\n",
              "      <td>03:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>1.177721</td>\n",
              "      <td>0.916728</td>\n",
              "      <td>0.837618</td>\n",
              "      <td>0.980402</td>\n",
              "      <td>03:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>1.137874</td>\n",
              "      <td>0.921226</td>\n",
              "      <td>0.836854</td>\n",
              "      <td>0.981166</td>\n",
              "      <td>03:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>1.119753</td>\n",
              "      <td>0.889027</td>\n",
              "      <td>0.852634</td>\n",
              "      <td>0.982184</td>\n",
              "      <td>03:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>1.078525</td>\n",
              "      <td>0.879967</td>\n",
              "      <td>0.854925</td>\n",
              "      <td>0.980402</td>\n",
              "      <td>03:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>1.086448</td>\n",
              "      <td>0.876130</td>\n",
              "      <td>0.856197</td>\n",
              "      <td>0.986002</td>\n",
              "      <td>03:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>1.078481</td>\n",
              "      <td>0.873087</td>\n",
              "      <td>0.859252</td>\n",
              "      <td>0.984220</td>\n",
              "      <td>03:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>1.060478</td>\n",
              "      <td>0.864646</td>\n",
              "      <td>0.861797</td>\n",
              "      <td>0.984729</td>\n",
              "      <td>03:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>1.070455</td>\n",
              "      <td>0.877990</td>\n",
              "      <td>0.855434</td>\n",
              "      <td>0.981166</td>\n",
              "      <td>03:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>1.060712</td>\n",
              "      <td>0.919138</td>\n",
              "      <td>0.842708</td>\n",
              "      <td>0.973530</td>\n",
              "      <td>03:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.037213</td>\n",
              "      <td>0.863578</td>\n",
              "      <td>0.860524</td>\n",
              "      <td>0.983456</td>\n",
              "      <td>03:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.993216</td>\n",
              "      <td>0.839465</td>\n",
              "      <td>0.875032</td>\n",
              "      <td>0.984220</td>\n",
              "      <td>03:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>1.000636</td>\n",
              "      <td>0.866359</td>\n",
              "      <td>0.866633</td>\n",
              "      <td>0.982438</td>\n",
              "      <td>03:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>1.000963</td>\n",
              "      <td>0.862262</td>\n",
              "      <td>0.865106</td>\n",
              "      <td>0.983965</td>\n",
              "      <td>03:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.980151</td>\n",
              "      <td>0.860585</td>\n",
              "      <td>0.867905</td>\n",
              "      <td>0.979384</td>\n",
              "      <td>03:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.983253</td>\n",
              "      <td>0.853133</td>\n",
              "      <td>0.866124</td>\n",
              "      <td>0.978875</td>\n",
              "      <td>03:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.967836</td>\n",
              "      <td>0.849953</td>\n",
              "      <td>0.867396</td>\n",
              "      <td>0.981420</td>\n",
              "      <td>03:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.964824</td>\n",
              "      <td>0.845048</td>\n",
              "      <td>0.869178</td>\n",
              "      <td>0.981166</td>\n",
              "      <td>03:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.973495</td>\n",
              "      <td>0.877584</td>\n",
              "      <td>0.857979</td>\n",
              "      <td>0.979130</td>\n",
              "      <td>03:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.959082</td>\n",
              "      <td>0.854361</td>\n",
              "      <td>0.865615</td>\n",
              "      <td>0.982438</td>\n",
              "      <td>03:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.951669</td>\n",
              "      <td>0.836488</td>\n",
              "      <td>0.872741</td>\n",
              "      <td>0.982184</td>\n",
              "      <td>03:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.934199</td>\n",
              "      <td>0.881932</td>\n",
              "      <td>0.856707</td>\n",
              "      <td>0.978366</td>\n",
              "      <td>03:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.939657</td>\n",
              "      <td>0.841742</td>\n",
              "      <td>0.872232</td>\n",
              "      <td>0.976584</td>\n",
              "      <td>03:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.947947</td>\n",
              "      <td>0.871577</td>\n",
              "      <td>0.856197</td>\n",
              "      <td>0.977093</td>\n",
              "      <td>03:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.945118</td>\n",
              "      <td>0.843204</td>\n",
              "      <td>0.871469</td>\n",
              "      <td>0.984474</td>\n",
              "      <td>03:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.902359</td>\n",
              "      <td>0.827922</td>\n",
              "      <td>0.874777</td>\n",
              "      <td>0.984474</td>\n",
              "      <td>03:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.943538</td>\n",
              "      <td>0.843466</td>\n",
              "      <td>0.865106</td>\n",
              "      <td>0.980657</td>\n",
              "      <td>03:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.938166</td>\n",
              "      <td>0.862651</td>\n",
              "      <td>0.868414</td>\n",
              "      <td>0.978112</td>\n",
              "      <td>03:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.916942</td>\n",
              "      <td>0.852099</td>\n",
              "      <td>0.865360</td>\n",
              "      <td>0.980657</td>\n",
              "      <td>03:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.913723</td>\n",
              "      <td>0.862059</td>\n",
              "      <td>0.860524</td>\n",
              "      <td>0.978112</td>\n",
              "      <td>03:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.904603</td>\n",
              "      <td>0.836636</td>\n",
              "      <td>0.869941</td>\n",
              "      <td>0.984220</td>\n",
              "      <td>03:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.913837</td>\n",
              "      <td>0.872514</td>\n",
              "      <td>0.860779</td>\n",
              "      <td>0.979384</td>\n",
              "      <td>03:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.928300</td>\n",
              "      <td>0.833836</td>\n",
              "      <td>0.867396</td>\n",
              "      <td>0.981929</td>\n",
              "      <td>03:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.893750</td>\n",
              "      <td>0.842413</td>\n",
              "      <td>0.875541</td>\n",
              "      <td>0.978366</td>\n",
              "      <td>03:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.896457</td>\n",
              "      <td>0.847855</td>\n",
              "      <td>0.866887</td>\n",
              "      <td>0.982693</td>\n",
              "      <td>03:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.918201</td>\n",
              "      <td>0.833293</td>\n",
              "      <td>0.867396</td>\n",
              "      <td>0.980657</td>\n",
              "      <td>03:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.928034</td>\n",
              "      <td>0.851654</td>\n",
              "      <td>0.863324</td>\n",
              "      <td>0.979639</td>\n",
              "      <td>03:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.902210</td>\n",
              "      <td>0.838160</td>\n",
              "      <td>0.872232</td>\n",
              "      <td>0.980148</td>\n",
              "      <td>03:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.910857</td>\n",
              "      <td>0.856207</td>\n",
              "      <td>0.868160</td>\n",
              "      <td>0.977857</td>\n",
              "      <td>03:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.910544</td>\n",
              "      <td>0.829440</td>\n",
              "      <td>0.872487</td>\n",
              "      <td>0.982184</td>\n",
              "      <td>03:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.881279</td>\n",
              "      <td>0.847890</td>\n",
              "      <td>0.864342</td>\n",
              "      <td>0.978366</td>\n",
              "      <td>03:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>0.879393</td>\n",
              "      <td>0.834673</td>\n",
              "      <td>0.876304</td>\n",
              "      <td>0.977093</td>\n",
              "      <td>03:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>0.869897</td>\n",
              "      <td>0.815108</td>\n",
              "      <td>0.879104</td>\n",
              "      <td>0.979893</td>\n",
              "      <td>03:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>0.873227</td>\n",
              "      <td>0.823586</td>\n",
              "      <td>0.878341</td>\n",
              "      <td>0.979130</td>\n",
              "      <td>03:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>0.884787</td>\n",
              "      <td>0.849825</td>\n",
              "      <td>0.865106</td>\n",
              "      <td>0.977093</td>\n",
              "      <td>03:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>0.900716</td>\n",
              "      <td>0.832583</td>\n",
              "      <td>0.874523</td>\n",
              "      <td>0.976584</td>\n",
              "      <td>03:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>0.902467</td>\n",
              "      <td>0.855592</td>\n",
              "      <td>0.863069</td>\n",
              "      <td>0.977348</td>\n",
              "      <td>03:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>0.895071</td>\n",
              "      <td>0.832150</td>\n",
              "      <td>0.875795</td>\n",
              "      <td>0.978621</td>\n",
              "      <td>03:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>0.888221</td>\n",
              "      <td>0.838937</td>\n",
              "      <td>0.870196</td>\n",
              "      <td>0.979384</td>\n",
              "      <td>03:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>0.899722</td>\n",
              "      <td>0.839806</td>\n",
              "      <td>0.874014</td>\n",
              "      <td>0.979384</td>\n",
              "      <td>03:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.849757</td>\n",
              "      <td>0.814254</td>\n",
              "      <td>0.878341</td>\n",
              "      <td>0.980657</td>\n",
              "      <td>03:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>61</td>\n",
              "      <td>0.843392</td>\n",
              "      <td>0.821580</td>\n",
              "      <td>0.880886</td>\n",
              "      <td>0.980402</td>\n",
              "      <td>03:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>0.848228</td>\n",
              "      <td>0.804020</td>\n",
              "      <td>0.886740</td>\n",
              "      <td>0.981166</td>\n",
              "      <td>03:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63</td>\n",
              "      <td>0.852713</td>\n",
              "      <td>0.819146</td>\n",
              "      <td>0.880122</td>\n",
              "      <td>0.981166</td>\n",
              "      <td>03:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>0.859669</td>\n",
              "      <td>0.813421</td>\n",
              "      <td>0.888267</td>\n",
              "      <td>0.978875</td>\n",
              "      <td>03:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>0.850570</td>\n",
              "      <td>0.809344</td>\n",
              "      <td>0.887249</td>\n",
              "      <td>0.979639</td>\n",
              "      <td>03:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>0.844106</td>\n",
              "      <td>0.810916</td>\n",
              "      <td>0.882413</td>\n",
              "      <td>0.979384</td>\n",
              "      <td>03:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>67</td>\n",
              "      <td>0.834975</td>\n",
              "      <td>0.786047</td>\n",
              "      <td>0.890557</td>\n",
              "      <td>0.982947</td>\n",
              "      <td>03:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68</td>\n",
              "      <td>0.815580</td>\n",
              "      <td>0.788566</td>\n",
              "      <td>0.891066</td>\n",
              "      <td>0.981675</td>\n",
              "      <td>03:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>69</td>\n",
              "      <td>0.813956</td>\n",
              "      <td>0.788125</td>\n",
              "      <td>0.890303</td>\n",
              "      <td>0.982438</td>\n",
              "      <td>03:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.800898</td>\n",
              "      <td>0.792375</td>\n",
              "      <td>0.889285</td>\n",
              "      <td>0.981929</td>\n",
              "      <td>03:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>71</td>\n",
              "      <td>0.792325</td>\n",
              "      <td>0.779657</td>\n",
              "      <td>0.898956</td>\n",
              "      <td>0.979130</td>\n",
              "      <td>03:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>0.793460</td>\n",
              "      <td>0.771873</td>\n",
              "      <td>0.899211</td>\n",
              "      <td>0.980402</td>\n",
              "      <td>03:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>73</td>\n",
              "      <td>0.792567</td>\n",
              "      <td>0.769582</td>\n",
              "      <td>0.898702</td>\n",
              "      <td>0.981929</td>\n",
              "      <td>03:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74</td>\n",
              "      <td>0.790220</td>\n",
              "      <td>0.764180</td>\n",
              "      <td>0.902011</td>\n",
              "      <td>0.980148</td>\n",
              "      <td>03:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>0.808702</td>\n",
              "      <td>0.759386</td>\n",
              "      <td>0.905319</td>\n",
              "      <td>0.981675</td>\n",
              "      <td>03:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>76</td>\n",
              "      <td>0.786981</td>\n",
              "      <td>0.755479</td>\n",
              "      <td>0.905065</td>\n",
              "      <td>0.981929</td>\n",
              "      <td>03:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>77</td>\n",
              "      <td>0.802998</td>\n",
              "      <td>0.755920</td>\n",
              "      <td>0.905319</td>\n",
              "      <td>0.981929</td>\n",
              "      <td>03:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>78</td>\n",
              "      <td>0.789846</td>\n",
              "      <td>0.752382</td>\n",
              "      <td>0.905574</td>\n",
              "      <td>0.983711</td>\n",
              "      <td>03:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>79</td>\n",
              "      <td>0.780742</td>\n",
              "      <td>0.753180</td>\n",
              "      <td>0.903792</td>\n",
              "      <td>0.982947</td>\n",
              "      <td>03:10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "80 epochs: 0.9008229374885559 (3 runs)\n",
            "depth multiplier=6 {80: 0.9008229374885559}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euDz8pVe_PDj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9a0c68e7-6788-4940-b4d4-ae20a9ed30ad"
      },
      "source": [
        "res"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{80: [0.902519702911377, 0.8961567878723145]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1r2zZgMmGK6i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "20df467a-c42b-4a00-e837-32f34db71b30"
      },
      "source": [
        "for i in range(80):\n",
        "  print(i, learn.recorder.val_losses[i].item(), learn.recorder.metrics[i][0].item())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 1.8019211292266846 0.40519216656684875\n",
            "1 1.5199214220046997 0.5612115263938904\n",
            "2 1.334391713142395 0.6543650031089783\n",
            "3 1.2439961433410645 0.6948332786560059\n",
            "4 1.1527239084243774 0.7291931509971619\n",
            "5 1.1206214427947998 0.7495545744895935\n",
            "6 1.052816390991211 0.7869687080383301\n",
            "7 1.0666406154632568 0.7770425081253052\n",
            "8 0.9904943704605103 0.8096207976341248\n",
            "9 1.0099091529846191 0.7938406467437744\n",
            "10 0.9543590545654297 0.824128270149231\n",
            "11 0.956939160823822 0.8218376040458679\n",
            "12 0.9327539205551147 0.8266734480857849\n",
            "13 0.9148764610290527 0.8327818512916565\n",
            "14 0.8986201882362366 0.8434716463088989\n",
            "15 0.9222990274429321 0.8376176953315735\n",
            "16 0.9147737622261047 0.8355816006660461\n",
            "17 0.9077925682067871 0.8429625630378723\n",
            "18 0.9136068820953369 0.8317638039588928\n",
            "19 0.8858543038368225 0.8600152730941772\n",
            "20 0.8733745813369751 0.8539068698883057\n",
            "21 0.8703872561454773 0.8551794290542603\n",
            "22 0.9229952692985535 0.8401628732681274\n",
            "23 0.8630534410476685 0.8577246069908142\n",
            "24 0.8858904838562012 0.8567065596580505\n",
            "25 0.8902508020401001 0.8457622528076172\n",
            "26 0.8780667781829834 0.8592517375946045\n",
            "27 0.8493083715438843 0.8686688542366028\n",
            "28 0.8931047320365906 0.8485620021820068\n",
            "29 0.8574698567390442 0.8638330101966858\n",
            "30 0.8555485606193542 0.8605242967605591\n",
            "31 0.8734908103942871 0.863069474697113\n",
            "32 0.8431901931762695 0.8668872714042664\n",
            "33 0.8450456857681274 0.8666327595710754\n",
            "34 0.8614643812179565 0.8620514273643494\n",
            "35 0.8520182967185974 0.8645966053009033\n",
            "36 0.8454185128211975 0.8689233660697937\n",
            "37 0.8613205552101135 0.8638330101966858\n",
            "38 0.857974112033844 0.863323986530304\n",
            "39 0.8505651950836182 0.8623059391975403\n",
            "40 0.856765866279602 0.865614652633667\n",
            "41 0.844211995601654 0.8689233660697937\n",
            "42 0.8655033111572266 0.8645966053009033\n",
            "43 0.8753456473350525 0.8592517375946045\n",
            "44 0.8610297441482544 0.8595062494277954\n",
            "45 0.8366169929504395 0.8742682337760925\n",
            "46 0.8516916036605835 0.8691779375076294\n",
            "47 0.8316229581832886 0.877577006816864\n",
            "48 0.8497086763381958 0.870450496673584\n",
            "49 0.8658488988876343 0.8635784983634949\n",
            "50 0.8440166711807251 0.8663781881332397\n",
            "51 0.8720356225967407 0.8615424036979675\n",
            "52 0.8709325790405273 0.8572155833244324\n",
            "53 0.8610175848007202 0.8648511171340942\n",
            "54 0.8346572518348694 0.870450496673584\n",
            "55 0.8362225890159607 0.8689233660697937\n",
            "56 0.8394232988357544 0.868159830570221\n",
            "57 0.8220009207725525 0.8783405423164368\n",
            "58 0.849245011806488 0.8663781881332397\n",
            "59 0.8524292707443237 0.8684143424034119\n",
            "60 0.8572558164596558 0.86790531873703\n",
            "61 0.8314514756202698 0.8808857202529907\n",
            "62 0.8429438471794128 0.877577006816864\n",
            "63 0.8523198366165161 0.8755408525466919\n",
            "64 0.837578296661377 0.8696869611740112\n",
            "65 0.8434638381004333 0.8717230558395386\n",
            "66 0.8091349601745605 0.8862305879592896\n",
            "67 0.8187283873558044 0.8791040778160095\n",
            "68 0.8100225329399109 0.8831763863563538\n",
            "69 0.8090624809265137 0.884958028793335\n",
            "70 0.8073403239250183 0.8841944336891174\n",
            "71 0.7952967286109924 0.8875032067298889\n",
            "72 0.7907714247703552 0.8910664319992065\n",
            "73 0.7880218029022217 0.8915754556655884\n",
            "74 0.7843579649925232 0.8938661217689514\n",
            "75 0.7771846652030945 0.8956477642059326\n",
            "76 0.7772098779678345 0.8956477642059326\n",
            "77 0.7761608958244324 0.8964112997055054\n",
            "78 0.7752765417098999 0.8959022760391235\n",
            "79 0.7749691009521484 0.8961567878723145\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZFJwVE_mW9n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}